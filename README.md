# Sign2Speach ‚Äì Traducci√≥n de Lengua de Signos a Voz mediante Computer Vision y Edge Computing

Este proyecto es el Trabajo de Fin de Grado (TFG) del grado en Ingenier√≠a Inform√°tica en la Universitat Polit√®cnica de Val√®ncia ‚Äì Campus de Alcoy.

## üéØ Objetivo

Desarrollar un sistema basado en **computer vision** que permita traducir secuencias de lengua de signos americana (ASL) en texto y posteriormente en voz, utilizando tecnolog√≠as de **edge computing** como la Coral TPU de Google.

## üß† Componentes del proyecto

### 1. `Entrenamiento/`
C√≥digo para:
- Preprocesamiento y extracci√≥n de landmarks con MediaPipe.
- Entrenamiento del modelo secuencial.
- Conversi√≥n del modelo a TFLite.

### 2. `sign2speech_app/`
Aplicaci√≥n desarrollada con **PyQt5** para:
- Capturar signos en tiempo real.
- Predecir palabras con el modelo TFLite.
- Formar frases con un LLM local.
- Convertir texto a voz (TTS).

### 3. `Codigo de Edge Tpu/`
Scripts y modelo optimizado (`model_edgetpu.tflite`) para ejecutar inferencia directamente en una Coral TPU conectada a servicios p√∫blicos u otros dispositivos embebidos.

